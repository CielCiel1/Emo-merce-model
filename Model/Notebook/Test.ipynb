{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Test.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"65TOTJBV1pdX","outputId":"0fc96576-2a70-4d4d-e259-aadb5ef8f448","executionInfo":{"status":"ok","timestamp":1654548810975,"user_tz":-420,"elapsed":19479,"user":{"displayName":"Trang Trần","userId":"07315778065686989197"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"MNiQZeDh4Xkl","outputId":"e376606e-b686-4b84-bd1c-ddcb0736a4c9","executionInfo":{"status":"ok","timestamp":1654548834542,"user_tz":-420,"elapsed":23573,"user":{"displayName":"Trang Trần","userId":"07315778065686989197"}}},"source":["!pip install transformers\n","!pip install fairseq\n","!pip install fastBPE"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 4.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 6.1 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 51.8 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 61.3 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fairseq\n","  Downloading fairseq-0.10.2-cp37-cp37m-manylinux1_x86_64.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 4.8 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq) (4.64.0)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq) (0.29.30)\n","Collecting sacrebleu>=1.4.12\n","  Downloading sacrebleu-2.1.0-py3-none-any.whl (92 kB)\n","\u001b[K     |████████████████████████████████| 92 kB 12.2 MB/s \n","\u001b[?25hCollecting dataclasses\n","  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n","Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.15.0)\n","Collecting hydra-core\n","  Downloading hydra_core-1.2.0-py3-none-any.whl (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 76.5 MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq) (2019.12.20)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.11.0+cu113)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.21.6)\n","Collecting portalocker\n","  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.8.9)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq) (2.21)\n","Collecting antlr4-python3-runtime==4.9.*\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[K     |████████████████████████████████| 117 kB 77.3 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq) (5.7.1)\n","Collecting omegaconf~=2.2\n","  Downloading omegaconf-2.2.2-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 8.9 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq) (21.3)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf~=2.2->hydra-core->fairseq) (6.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core->fairseq) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->hydra-core->fairseq) (3.0.9)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->fairseq) (4.2.0)\n","Building wheels for collected packages: antlr4-python3-runtime\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=4e47e52057dada432372ab52058dce0c8c678aecc274a292218b87e3e7c2662e\n","  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n","Successfully built antlr4-python3-runtime\n","Installing collected packages: antlr4-python3-runtime, portalocker, omegaconf, colorama, sacrebleu, hydra-core, dataclasses, fairseq\n","Successfully installed antlr4-python3-runtime-4.9.3 colorama-0.4.4 dataclasses-0.6 fairseq-0.10.2 hydra-core-1.2.0 omegaconf-2.2.2 portalocker-2.4.0 sacrebleu-2.1.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pydevd_plugins"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fastBPE\n","  Downloading fastBPE-0.1.0.tar.gz (35 kB)\n","Building wheels for collected packages: fastBPE\n","  Building wheel for fastBPE (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fastBPE: filename=fastBPE-0.1.0-cp37-cp37m-linux_x86_64.whl size=483885 sha256=058b867b2b12185626e9c2d329a92e57fe404275e34fe10195e7500fe411b42c\n","  Stored in directory: /root/.cache/pip/wheels/bd/d4/0e/0d317a65f77d3f8049fedd8a2ee0519164cf3e6bd77ef886f1\n","Successfully built fastBPE\n","Installing collected packages: fastBPE\n","Successfully installed fastBPE-0.1.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ynmdz9ZHzjZ7","outputId":"a642ba32-2926-4b18-9151-670ed63fe6dd","executionInfo":{"status":"ok","timestamp":1654548848322,"user_tz":-420,"elapsed":13795,"user":{"displayName":"Trang Trần","userId":"07315778065686989197"}}},"source":["!git clone https://github.com/vncorenlp/VnCoreNLP\n","!pip install vncorenlp"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'VnCoreNLP'...\n","remote: Enumerating objects: 218, done.\u001b[K\n","remote: Counting objects: 100% (6/6), done.\u001b[K\n","remote: Compressing objects: 100% (6/6), done.\u001b[K\n","remote: Total 218 (delta 2), reused 1 (delta 0), pack-reused 212\u001b[K\n","Receiving objects: 100% (218/218), 214.22 MiB | 40.72 MiB/s, done.\n","Resolving deltas: 100% (78/78), done.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting vncorenlp\n","  Downloading vncorenlp-1.0.3.tar.gz (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 3.9 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vncorenlp) (2.23.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (2022.5.18.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (2.10)\n","Building wheels for collected packages: vncorenlp\n","  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-py3-none-any.whl size=2645951 sha256=69051377f6df78c69357131afe2a5c5bf4ec1ae04ed57e2eb1dcc5f5c08808bf\n","  Stored in directory: /root/.cache/pip/wheels/0c/d8/f2/d28d97379b4f6479bf51247c8dfd57fa00932fa7a74b6aab29\n","Successfully built vncorenlp\n","Installing collected packages: vncorenlp\n","Successfully installed vncorenlp-1.0.3\n"]}]},{"cell_type":"code","metadata":{"id":"7jiA5nJZzZ1J","executionInfo":{"status":"ok","timestamp":1654548855335,"user_tz":-420,"elapsed":7028,"user":{"displayName":"Trang Trần","userId":"07315778065686989197"}}},"source":["from transformers import RobertaForSequenceClassification, RobertaConfig\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from fairseq.data.encoders.fastbpe import fastBPE\n","from fairseq.data import Dictionary\n","from vncorenlp import VnCoreNLP\n","import pandas as pd\n","import argparse\n","import torch\n","import re"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vyyb9SI-ULuV","executionInfo":{"status":"ok","timestamp":1654548996819,"user_tz":-420,"elapsed":22306,"user":{"displayName":"Trang Trần","userId":"07315778065686989197"}}},"source":["path_config  = '/content/drive/MyDrive/Shopee_comment_ranking/4/config.json'\n","path_model = '/content/drive/MyDrive/Shopee_comment_ranking/4/pytorch_model.bin'\n","path_bpe = '/content/drive/MyDrive/Shopee_comment_ranking/PhoBERT_base_transformers/bpe.codes'\n","path_vocab = '/content/drive/MyDrive/Shopee_comment_ranking/PhoBERT_base_transformers/dict.txt'\n","\n","def get_model(path_model= None, path_config = None, path_bpe = None, path_vocab = None):\n","  config = RobertaConfig.from_pretrained(\n","      path_config, from_tf=False, num_labels = 2, output_hidden_states=False,\n","  )\n","  BERT_SA_NEW = RobertaForSequenceClassification.from_pretrained(\n","      path_model,\n","      config=config\n","  )\n","  BERT_SA_NEW.cuda()\n","  BERT_SA_NEW.eval()\n","\n","\n","  try:\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--bpe-codes', \n","        default=path_bpe,\n","        required=False,\n","        type=str,\n","        help='path to fastBPE BPE'\n","    )\n","    args, unknown = parser.parse_known_args()\n","    bpe = fastBPE(args)\n","  except:\n","    bpe = None\n","    print(\"load bpe fail\")\n","\n","  try:\n","    vocab = Dictionary()\n","    vocab.add_from_file(path_vocab)\n","  except:\n","    vocab=None\n","    print('load vocab fail')\n","  return BERT_SA_NEW, bpe, vocab\n","\n","model, bpe, vocab = get_model(path_model, path_config, path_bpe, path_vocab)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"LYP5tUsUTqH0","executionInfo":{"status":"ok","timestamp":1654549027402,"user_tz":-420,"elapsed":30586,"user":{"displayName":"Trang Trần","userId":"07315778065686989197"}}},"source":["rdrsegmenter = VnCoreNLP(\"VnCoreNLP/VnCoreNLP-1.1.1.jar\", annotators=\"wseg,pos,ner\", max_heap_size='-Xmx2g')"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"XW4reS4J00J_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654549028298,"user_tz":-420,"elapsed":909,"user":{"displayName":"Trang Trần","userId":"07315778065686989197"}},"outputId":"55b3a413-bf28-432e-b8ff-4240c3b5f3d9"},"source":["macp = pd.read_excel('/content/drive/MyDrive/Shopee_comment_ranking/teencode.xlsx')\n","\n","teencod = {}\n","\n","dung = macp['Từ đúng'].tolist()\n","code_char = macp['Teencod'].tolist()\n","for i in range(len(code_char)):\n","  teencod[code_char[i]] = dung[i]\n","print(teencod)\n","\n","\n","def del_test(text):\n","  year = ['năm 2021', 'năm 2020', 'năm 2019', 'năm 2018', 'năm 2017', 'năm 2016', 'năm 2015', 'năm 2014', 'năm 2013', 'năm 2012', 'năm 2011', 'năm 2010', 'Năm 2021', 'Năm 2020', 'Năm 2019', 'Năm 2018', 'Năm 2017', 'Năm 2016', 'Năm 2015', 'Năm 2014', 'Năm 2013', 'Năm 2012', 'Năm 2011', 'Năm 2010', '2021', '2020', '2019', '2018', '2017', '2016', '2015', '2014', '2013', '2012', '2011', '2010']\n","  month = ['tháng 1', 'tháng 2', 'tháng 3', 'tháng 4', 'tháng 5', 'tháng 6', 'tháng 7', 'tháng 8', 'tháng 9', 'tháng 10', 'tháng 11', 'tháng 12', 'Tháng 1', 'Tháng 2', 'Tháng 3', 'Tháng 4', 'Tháng 5', 'Tháng 6', 'Tháng 7', 'Tháng 8', 'Tháng 9', 'Tháng 10', 'Tháng 11', 'tháng 12']\n","  quy = ['quý 1', 'quý 2', 'quý 3', 'quý 4', 'Quý 1', 'Quý 2', 'Quý 3', 'Quý 4']\n","  text = text.replace('Covid-19', 'Covid')\n","  word_segmented_text = rdrsegmenter.ner(text)[0]\n","  for char, typ in word_segmented_text:\n","    if typ == 'B-ORG' or typ == 'I-ORG' or typ == 'B-PER' or typ == 'I-PER':\n","      char = char.replace('_', ' ')\n","      text = text.replace(char, 'name')\n","    if typ == \"B-LOC\" or typ == \"I-LOC\":\n","      if char != 'VN':\n","        char = char.replace('_', ' ')\n","        text = text.replace(char,'loc')\n","    if typ == 'O':\n","      if len(re.findall('\\d*\\.?\\,?\\d+\\%', char)) > 0:\n","        text = text.replace(char, 'percent')\n","      # if len(re.findall('\\s?\\(?[A-Z]{3,4}\\)?\\s?', char)) > 0 and char != 'USD' and char != 'SHOP':\n","      #     text = text.replace(char, 'name')\n","      if char in teencod.keys():\n","        text = text.replace(char, teencod[char])\n","      # char = char.replace('_', ' ')\n","      # char_lower = char.lower()\n","      # if char_lower in tenct:\n","      #   text = text.replace(char, 'name')\n","  text = text.replace('\"', '')\n","  text = text.replace('”', '')\n","  text = text.replace('“', '')\n","  text = text.replace('.', ' ')\n","  text = text.replace(',', '')\n","  text = text.replace('(', '')\n","  text = text.replace(')', '')\n","  text = text.replace(':', '')\n","  text = text.replace('[', '')\n","  text = text.replace(']', '')\n","  text = text.replace('-', ' ')\n","  text = re.sub('\\d{0,2}-?\\d{0,2}\\/\\d{1,4}', 'date', text)\n","  for i in quy:\n","    text = text.replace(i, 'date')\n","  for i in year:\n","    text = text.replace(i, 'date')\n","  for i in month:\n","    text = text.replace(i, 'date')\n","  text = re.sub('\\d+ năm ', 'date ', text)\n","  text = re.sub('\\d+ tháng ', 'date ', text)\n","  text = re.sub(' \\-?\\d+\\w?', ' number', text)\n","  text = text.split()\n","  for i in range(len(text)):\n","    if text[i].isdigit():\n","      text[i] = 'number'\n","  text = ' '.join(text)\n","  text1 = text.split()\n","  # for i in range(len(text1)+1):\n","  #   try:\n","  #     if text1[i][0].isupper() and text1[i+1][0].isupper():\n","  #       text = text.replace(text1[i], 'name')\n","  #       text = text.replace(text1[i+1], 'name')\n","  #   except:\n","  #     pass\n","  text = rdrsegmenter.tokenize(text)\n","  text = ' '.join([' '.join(x) for x in text])\n","  text = text.lower()\n","  return text"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["{'ctrai': 'con trai', 'khôg': 'không', 'bme': 'bố mẹ', 'cta': 'chúng ta', 'mih': 'mình', 'mqh': 'mối quan hệ', 'cgai': 'con gái', 'nhữg': 'những', 'mng': 'mọi người', 'svtn': 'sinh viên tình nguyện', 'r ': 'rồi', 'qtam': 'quan tâm', 'thươg': 'thương', 'qtâm': 'quan tâm', 'chug': 'chung', 'trườg': 'trường', 'thoy': 'thôi', 'đki': 'đăng ký', 'atsm': 'ảo tưởng sức mạnh', 'ạk': 'ạ', 'cv': 'công việc', 'vch': 'vãi chưởng', 'cùg': 'cùng', 'pn': 'bạn', 'pjt': 'biết', 'thjk': 'thích', 'keke': 'ce ce', 'ktra': 'kiểm tra', 'nek': 'nè', 'cgái': 'con gái', 'nthe': 'như thế', 'chúg': 'chúng', 'kái': 'cái', 'tìh': 'tình', 'phòg': 'phòng', 'lòg': 'lòng', 'từg': 'từng', 'rằg': 'rằng', 'sốg': 'sống', 'thuj': 'thôi', 'thuơng': 'thương', 'càg': 'càng', 'đky': 'đăng ký', 'bằg': 'bằng', 'sviên': 'sinh viên', 'ák': 'á', 'đág': 'đáng', 'nvay': 'như vậy', 'nhjeu': 'nhiều', 'xg': 'xuống', 'zồi': 'rồi', 'trag': 'trang', 'zữ': 'dữ', 'atrai': 'anh trai', 'kte': 'kinh tế', 'độg': 'động', 'lmht': 'liên minh huyền thoại', 'gắg': 'gắng', 'đzai': 'đẹp trai', 'thgian': 'thời gian', 'plz': 'pờ ly', 'đồg': 'đồng', 'btrai': 'bạn trai', 'nthê': 'như thế', 'hìhì': 'hì hì', 'vọg': 'vọng', 'hihe': 'hi he', 'đôg': 'đông', 'răg': 'răng', 'thườg': 'thường', 'tcảm': 'tình cảm', 'đứg': 'đứng', 'ksao': 'không sao', 'dz': 'đẹp trai', 'hjxhjx': 'hix hix', 'cmày': 'chúng mày', 'xuốg': 'xuống', 'nkư': 'như', 'lquan': 'liên quan', 'tiếg': 'tiếng', 'hajz': 'hai', 'xih': 'xinh', 'hìh': 'hình', 'thàh': 'thành', 'ngke': 'nghe', 'dzậy': 'dậy', 'teencode': 'tin cốt', 'tnào': 'thế nào', 'tưởg': 'tưởng', 'ctrinh': 'chương trình', 'phog': 'phong', 'hôg': 'không', 'zìa': 'gì', 'kũg': 'cũng', 'ntnao': 'như thế nào', 'trọg': 'trọng', 'nthế': 'như thế', 'năg': 'năng', 'ngđó': 'người đó', 'lquen': 'làm quen', 'riêg': 'riêng', 'ngag': 'ngang', 'hêhê': 'hê hê', 'bnhiu': 'bao nhiêu', 'ngốk': 'ngốc', 'kậu': 'cậu', 'highland': 'hai lừn', 'kqua': 'kết quả', 'htrc': 'hôm trước', 'địh': 'định', 'gđình': 'gia đinh', 'giốg': 'giống', 'csống': 'cuộc sống', 'xug': 'xùng', 'zùi': 'rồi', 'bnhiêu': 'bao nhiêu', 'cbị': 'chuẩn bị', 'kòn': 'còn', 'buôg': 'buông', 'csong': 'cuộc sống', 'chàg': 'chàng', 'chăg': 'chăng', 'ngàh': 'ngành', 'llac': 'liên lạc', 'nkưng': 'nhưng', 'nắg': 'nắng', 'tíh': 'tính', 'khoảg': 'khoảng', 'thík': 'thích', 'ngđo': 'người đó', 'ngkhác': 'người khác', 'thẳg': 'thẳng', 'kảm': 'cảm', 'dàh': 'dành', 'júp': 'giúp', 'lặg': 'lặng', 'vđê': 'vấn đề', 'bbè': 'bạn bè', 'bóg': 'bóng', 'dky': 'đăng ký', 'dòg': 'dòng', 'uốg': 'uống', 'tyêu': 'tình yêu', 'snvv': 'sinh nhật vui vẻ', 'đthoại': 'điện thoại', 'qhe': 'quan hệ', 'cviec': 'công việc', 'tượg': 'tượng', 'qà': 'quà', 'thjc': 'thích', 'nhưq': 'nhưng', 'cđời': 'cuộc đời', 'bthường': 'bình thường', 'zà': 'già', 'đáh': 'đánh', 'xloi': 'xin lỗi', 'zám': 'dám', 'qtrọng': 'quan trọng', 'bìh': 'bình', 'lzi': 'làm gì', 'qhệ': 'quan hệ', 'đhbkhn': 'đại học bách khoa hà nội', 'hajzz': 'hai', 'kủa': 'của', 'lz': 'làm gì', 'đhkhtn': 'đại học khoa học tự nhiên', 'đóg': 'đóng', 'cka': 'cha', 'lgi': 'làm gì', 'nvậy': 'như vậy', 'qả': 'quả', 'đkiện': 'điều kiện', 'nèk': 'nè', 'tlai': 'tương lai', 'bsĩ': 'bác sĩ', 'hkì': 'học kỳ', 'đcsvn': 'đảng cộng sản việt nam', 'vde': 'vấn đề', 'chta': 'chúng ta', 'òy': 'rồi', 'ltinh': 'linh tinh', 'ngyeu': 'người yêu', 'đthoai': 'điện thoại', 'snghĩ': 'suy nghĩ', 'nặg': 'nặng', 'họk': 'học', 'dừg': 'dừng', 'hphúc': 'hạnh phúc', 'hiha': 'hi ha', 'wtâm': 'quan tâm', 'thíck': 'thích', 'chuện': 'chuyện', 'lạh': 'lạnh', 'fây': 'phây', 'ntnày': 'như thế này', 'lúk': 'lúc', 'haj': 'hai', 'ngía': 'nghía', 'mớj': 'mới', 'hsơ': 'hồ sơ', 'ctraj': 'con trai', 'nyêu': 'người yêu', 'điiiiiii': 'đi', 'rồii': 'rồi', 'c ': 'chị', 'kih': 'kinh', 'kb': 'kết bạn', 'hixxx': 'hích', 'dthương': 'dễ thương', 'nhiềuuu': 'nhiều', 'ctrình': 'chương trình', 'mìnk': 'mình', 'mjh': 'mình', 'ng': 'người', 'vc': 'vợ chồng', 'uhm': 'ừm', 'thỳ': 'thì', 'nyc': 'người yêu cũ', 'tks': 'thanks', 'nàg': 'nàng', 'thôii': 'thôi', 'đjên': 'điên', 'bgái': 'bạn gái', 'vớii': 'với', 'xink': 'xinh', 'hđộng': 'hành động', 'đhọc': 'đại học', 'mk': 'mình', 'bn': 'bạn', 'thik': 'thích', 'cj': 'chị', 'mn': 'mọi người', 'nguoi': 'người', 'nógn': 'nóng', 'hok': 'không', 'ko': 'không', 'bik': 'biết', 'vs': 'với', 'cx': 'cũng', 'mik': 'mình', 'wtf': 'what the fuck', 'đc': 'được', 'cmt': 'comment', 'ck': 'chồng', 'chk': 'chồng', 'ngta': 'người ta', 'gđ': 'gia đình', 'oh': 'ồ', 'vk': 'vợ', 'ctác': 'công tác', 'sg': 'sài gòn', 'ae': 'anh em', 'ah': 'à', 'ạh': 'ạ', 'rì': 'gì', 'ms': 'mới', 'vn': 'việt nam', 'nhaa': 'nha', 'cũg': 'cũng', 'đag': 'đang', 'ơiii': 'ơi', 'hic': 'hích', 'ace': 'anh chị em', 'àk': 'à', 'uh': 'ừ', 'cmm': 'con mẹ mày', 'cmnr': 'con mẹ nó rồi', 'ơiiii': 'ơi', 'hnay': 'hôm nay', 'ukm': 'ừm', 'tq': 'trung quốc', 'ctr': 'chương trình', 'đii': 'đi', 'nch': 'nói chuyện', 'trieu': 'triệu', 'hahah': 'ha ha', 'nta': 'người ta', 'ngèo': 'nghèo', 'kêh': 'kênh', 'ak': 'à', 'ad': 'admin', 'j ': 'gì', 'ny': 'người yêu', 'dc': 'được', 'qc': 'quảng cáo', 'baoh': 'bao giờ', 'zui': 'vui', 'zẻ': 'vẻ', 'tym': 'tim', 'aye': 'anh yêu em', 'eya': 'em yêu anh', 'fb': 'facebook', 'insta': 'instagram', 'z ': 'vậy', 'thich': 'thích', 'vcl': 'vờ cờ lờ', 'đt': 'điện thoại', 'acc': 'account', 'lol': 'lồn', 'loz': 'lồn', 'lozz': 'lồn', 'trc': 'trước', 'chs': 'chẳng hiểu sao', 'đhs': 'đéo hiểu sao', 'qá': 'quá', 'ntn': 'như thế nào', 'wá': 'quá', 'zậy': 'vậy', 'zô': 'dô', 'ytb': 'youtube', 'vđ': 'vãi đái', 'vchg': 'vãi chưởng', 'sml': 'sấp mặt lờ', 'xl': 'xin lỗi', 'cmn': 'con mẹ nó', 'face': 'facebook', 'hjhj': 'hi hi', 'vv': 'vui vẻ', 'ns': 'nói', 'iu': 'yêu', 'vcđ': 'vãi cả đái', 'in4': 'info', 'qq': 'quằn què', 'sub': 'subcribe', 'kh': 'không', 'zạ': 'vậy', 'oy': 'rồi', 'jo': 'giờ', 'clmm': 'cái lồn mẹ mày', 'bsvv': 'buổi sáng vui vẻ', 'troai': 'trai', 'wa': 'quá', 'hjx': 'hix', 'e ': 'em', 'ik': 'ý', 'ji': 'gì', 'ce': 'chị em', 'lm': 'làm', 'đz': 'đẹp giai', 'sr': 'sorry', 'ib': 'inbox', 'hoy': 'thôi', 'đbh': 'đéo bao giờ', 'k ': 'không', 'vd': 'ví dụ', 'a ': 'anh', 'cũng z': 'cũng vậy', 'z là': 'vậy là', 'unf': 'unfriend', 'my fen': 'my friend', 'fen': 'friend', 'cty': 'công ty', 'on lai': 'online', 'u hai ba': 'u23', 'kô': 'không', 'đtqg': 'đội tuyển quốc gia', 'hqua': 'hôm qua', 'xog': 'xong', 'uk': 'ừ', 'nhoé': 'nhé', 'biet': 'biết', 'quí': 'quý', 'stk': 'số tài khoản', 'hong kong': 'hồng kông', 'đươc': 'được', 'nghành': 'ngành', 'nvqs': 'nghĩa vụ quân sự', 'ngừoi': 'người', 'trog': 'trong', 'tgian': 'thời gian', 'biêt': 'biết', 'fải': 'phải', 'nguời': 'người', 'tđn': 'thế đéo nào', 'bth': 'bình thường', 'tgdd': 'thế giới di động', 'khg': 'không', 'nhưg': 'nhưng', 'thpt': 'trung học phổ thông', 'thằg': 'thằng', 'đuợc': 'được', 'àh': 'à', 'ku': 'cu', 'thým': 'thím', 'onl': 'online', 'zú': 'vú', 'cmnd': 'chứng minh nhân dân', 'sđt': 'số điện thoại', 'klq': 'không liên quan', 'sp': 'sản phẩm', 'vkl': ' ', 'ibox': 'liên hệ', 'fs': 'miễn phí giao hàng', 'laf': 'là', 'shop': 'cửa hàng', 'shipper': 'người giao hàng', 'đk': 'được', 'yc': 'yêu cầu', 'y/c': 'yêu cầu', 'y c': 'yêu cầu'}\n"]}]},{"cell_type":"code","metadata":{"id":"1ohMK4yDy9e8","executionInfo":{"status":"ok","timestamp":1654549028299,"user_tz":-420,"elapsed":15,"user":{"displayName":"Trang Trần","userId":"07315778065686989197"}}},"source":["def predict(model, bpe, sense, vocab):\n","  subwords = '<s> ' + bpe.encode(sense) + ' </s>'\n","  encoded_sent = vocab.encode_line(subwords, append_eos=True, add_if_not_exist=False).long().tolist()\n","  encoded_sent = pad_sequences([encoded_sent], maxlen=195, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n","  mask = [int(token_id > 0) for token_id in encoded_sent[0]]\n","\n","\n","  encoded_sent = torch.tensor(encoded_sent).cuda()\n","  mask = torch.tensor(mask).cuda()\n","  encoded_sent = torch.reshape(encoded_sent, (1, 195))\n","  mask = torch.reshape(mask, (1, 195))\n","\n","  with torch.no_grad():\n","    outputs = model(encoded_sent, \n","      token_type_ids=None, \n","      attention_mask=mask)\n","    logits = outputs[0]\n","  return int(torch.argmax(logits))\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"4f1tSTl1zBr6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"32b4727c-14a1-42ae-95f6-c9c98995cf53","executionInfo":{"status":"ok","timestamp":1654549028748,"user_tz":-420,"elapsed":462,"user":{"displayName":"Trang Trần","userId":"07315778065686989197"}}},"source":["sent = 'sản phẩm bị lỗi không cắm được tai nghe vào, shop giao không đúng màu'\n","predict(model, bpe, sent, vocab)"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["sent = 'sản phẩm tốt, giao hàng nhanh'\n","predict(model, bpe, sent, vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P1dM-xtnziMx","executionInfo":{"status":"ok","timestamp":1654549052077,"user_tz":-420,"elapsed":372,"user":{"displayName":"Trang Trần","userId":"07315778065686989197"}},"outputId":"b3a41939-4912-4924-8462-c304dd821bad"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":[""],"metadata":{"id":"4tTU93sEzvZo"},"execution_count":null,"outputs":[]}]}